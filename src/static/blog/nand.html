<h1>Why Sheffer's Stroke is NAND instead of NOR</h1>
<p>
As a young boy, diving into mathematics was a great release for me. I often manipulated numbers in my head, independently discovered cross-multiplication, and found the gradeschool introduction to logic fascinating. Logic, of course, one needs to understand intuitively in order to be an effective coder.
</p><p>
Famous science personalities were my heroes. From Newton himself playing with equations of planetary motion in his giant Principia tome, to Godel showing with marvelous simplicity that all mathematical investigation will be (hopelessly?) incomplete, to Hoffstadter's work on artificial intelligence (and from whom I first heard the word "meme"), to Feynman picking locks at Los Alamos for kicks and investigating what he found interesting with little regard to its future practical value.
</p><p>
These were the giants to be revered, the Atlases holding the world on their shoulders. If only we could all be like them, forgoing our petty disagreements, cults of personality, and clanishness... or so I thought. Later when I realized that the science and maths world contained all of these things, it was quite disillusioning. Yes, even the greats stepped on each other's work, stole each other's credit, and disagreed on basic notation and phraseology of important concepts, particularly as a new field was being developed.
</p><p>
"Sheffer's Stroke" is an example of this kind of thing. Denoted by "|" (or "pipe" as we techies call it), in modern notation it refers to the logical NAND function. <i>a|b</i> is true in all cases where <i>a</i> and <i>b</i> are not both true. However, Henry Sheffer explicitly refers to his proposed function as "neither-nor", false in all cases where <i>a</i> and <i>b</i> are not both false. In his 1913 paper <a href="http://www.ams.org/journals/tran/1913-014-04/S0002-9947-1913-1500960-1/S0002-9947-1913-1500960-1.pdf">"A set of five independent postulates for Boolean algebras, with application to logical constants"</a>, he has this to say:
</p>
<a name='more'></a>
<p>
<img src="https://lh4.googleusercontent.com/-j9D5H8yPYMk/UUEdhPiA6DI/AAAAAAAAD98/7LEax1l-0OY/s673/perDef.PNG" />
</p><p>
Logic gate diagrams of either NAND or NOR can be used to express most of the definitions in Sheffer's paper by virtue of <a href="http://en.wikipedia.org/wiki/De_Morgan%27s_laws">De Morgan duality</a>. Most, but not all. Specifically, proof IIa:
</p><p>
<img src="https://lh4.googleusercontent.com/-XeL91GHsOok/UUEdhXpVtvI/AAAAAAAAD-A/0z-d_u_Nl8k/s459/zNand.PNG" />
</p><p>
Here <i>z</i> refers to 0, or false, where <i>u</i> (unity/unary) is 1, or true. If z refers to 0, then IIa only works for NOR.
</p><p>
Jean Nicand, however, found a reason for preferring NAND. In his 1917 paper, <a href="http://en.wikisource.org/wiki/A_Reduction_in_the_number_of_the_Primitive_Propositions_of_Logic">"A Reduction in the Number of Primitive Propositions of Logic"</a>, the following paragraphs which suggested an alternate function should be assigned to the stroke:
</p><p>
<img src="https://lh6.googleusercontent.com/-15l4UXPlS8k/UUEdhSPzTII/AAAAAAAAD-E/9XhNBPwpzz8/s518/whyNand.PNG" />
</p><p>
This takes a little decoding. Let's start with the symbols:
</p>
<pre><code>
~  NOT
&#8226; AND
&or; OR
&sup; Implies (modern notation is an arrow, &rarr;)
/|<b>|</b> The proposed new function, in order of operation if they are chained together
</code></pre>
<p>
So there are two options for | proposed by Nicand. The first:
</p>
<pre><code>
~p &#8226; ~q = (NOT p) AND (NOT q) := pq f
                                 00 1
                                 01 0
                                 10 0
                                 11 0
</code></pre>
<p>
This is the NOR function, what Nicand confusingly calls the "AND-form". The second option:
</p>
<pre><code>
~p &or; ~p = (NOT p) OR (NOT q) := pq f       
                                00 1       
                                01 1       
                                10 1       
                                11 0
</code></pre>
<p>
This is the NAND function, what Nicand calls the "OR-form". The "Implies" function takes a little explaining if you know logic mainly from coding. It has this truth table:
</p>
<pre><code>
pq &sup;
00 1
01 1
10 0
11 1
</code></pre>
<p>
It is false only if the first input (the cause) is true, but the second input (the effect) is false. Let's assert this proposition: if I punch you in the nose, your nose will bleed. Punching will be <i>p</i>, bleeding will be <i>q</i>. Only if <i>p</i> is true (I punch you), and <i>q</i> is false (you don't bleed) will my assertion be false. If I haven't hit you, your nose may or may not be bleeding for other reasons, so this doesn't disprove the assertion. If you don't care for the whole causality discussion, this function can also be thought of as "<i>p</i> is less than or equal to <i>q</i>".
</p><p>
Now, if we take Nicand's last statement, that expressing &sup; is p|q/q for NAND, and p/p|q<b>|</b>p/p| q for NOR, and turn those into logic gate diagrams, we see that the two functions are more similar than the notation would suggest:
</p><p>
<img src="https://lh4.googleusercontent.com/-vuc4Or75TCI/UUEdg7W-3WI/AAAAAAAAD9w/qdI5asc3wV0/s326/nandImplies.PNG" /><br />
<img src="https://lh4.googleusercontent.com/-fEA4UF3XEDw/UUEdg8MVASI/AAAAAAAAD9o/N5Fcao87P8M/s453/norImplies.PNG" />
</p><p>
Basically the NOR form just needs to reverse its outputs by using the first rule put forth by Sheffer:
</p><p>
<img src="https://lh4.googleusercontent.com/-T_kYFq_Opns/UUEdg2ZW5SI/AAAAAAAAD-I/ht7hq-OR704/s278/def2.PNG" />
</p><p>
However, the world adopted Nicand's view that Sheffer's definition should be changed, making it very confusing if you're a 40 year old software developer who didn't major in mathematics trying to wade through these papers for the first time. This isn't necessarily a bad thing. The NOR function didn't disappear from logic, and Sheffer's contribution is still of monumental importance, as chaining NAND or NOR gates in semiconductors to build more complex logical operations is exactly what makes them work. It's how math is performed, it's how RAM is stored. It's everything.
</p><p>
Point being, scientists step on each others toes and take liberties with their works in a very human fashion, further cementing my views that close examination of any hero will show things that are disappointing, and that the study of maths, like the study of computer science, is as much the study of history and notation as anything else.
</p>
